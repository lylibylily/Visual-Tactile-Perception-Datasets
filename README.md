# Visual-Tactile Perception Datasets

This repository aggregates publicly available visual-tactile datasets categorized by tactile data modality:

1. [Tactile Image-Based Datasets](#1-tactile-image-based-datasets)
2. [Numerical Tactile Signal-Based Datasets](#2-numerical-tactile-signal-based-datasets)
3. [Thermal Imaging Contact Datasets](#3-thermal-imaging-contact-datasets)

## 1. Tactile Image-Based Datasets

### ObjectFolder Family

**ObjectFolder**
- Source: *ObjectFolder: A Dataset of Objects with Implicit Visual, Auditory, and Tactile Representations*
- Download: Available in [ObjectFolder 2.0](#objectfolder-20)

**ObjectFolder 2.0**
- Source: *ObjectFolder 2.0: A Multisensory Object Dataset for Sim2Real Transfer*
- Download: [Stanford ObjectFolder 2.0](https://objectfolder.stanford.edu/objectfolder2-0-download)

**ObjectFolder-Real**
- Source: *The ObjectFolder Benchmark: Multisensory Learning with Neural and Real Objects*
- Download: [Real-World Data](https://objectfolder.stanford.edu/objectfolder-real-download)

**GelFabric**
- Source: *Connecting Look and Feel: Associating the visual and tactile properties of physical materials*
- Download: [MIT GelFabric Dataset](http://people.csail.mit.edu/yuan_wz/fabricdata/GelFabric.tar.gz)

**ViTac Cloth (ViTac)**
- Source: *ViTac: Feature Sharing Between Vision and Tactile Sensing for Cloth Texture Recognition*
- Download: [Google Drive](https://drive.google.com/file/d/1uYy4JguBlEeTllF9Ch6ZRixsTprGPpVJ/view?usp=sharing)

**Clothing Dataset**
- Source: *Active Clothing Material Perception Using Tactile Sensing and Deep Learning*
- Download: [MIT Active Clothing Data](https://data.csail.mit.edu/active_clothing/Data_ICRA18.tar)

**Visual-tactile Object Tracking Dataset**
- Source: *Enhancing Generalizable 6D Pose Tracking of an In-Hand Object with Tactile Sensing*
- Download: [OneDrive](https://1drv.ms/f/s!Ap-t7dLl7BFUaQ794lX1srGnwlQ?e=JgohXw)

**PoseIt**
- Source: *PoseIt: A Visual-Tactile Dataset of Holding Poses for Grasp Stability Analysis*
- Download: [CMU PoseIt](https://github.com/CMURoboTouch/PoseIt)

**The Feeling of Success**
- Source: *The feeling of success: Does touch sensing help predict grasp outcomes?*
- Download: [Project Page](https://sites.google.com/view/the-feeling-of-success/)

**Touch and Go**
- Source: *Touch and Go: Learning from Human-Collected Vision and Touch*
- Download: [Google Drive](https://drive.google.com/drive/folders/1NDasyshDCL9aaQzxjn_-Q5MBURRT360B)

**Slip Detection**
- Source: *Slip Detection with Combined Tactile and Visual Information*
- Download: [GitHub Repo](https://github.com/wkoa/slip_detection)

**More Than a Feeling**
- Source: *More Than a Feeling: Learning to Grasp and Regrasp Using Vision and Touch*
- Download: [Project Page](https://sites.google.com/view/more-than-a-feeling)

**VisGel**
- Source: *Connecting touch and vision via cross-modal prediction*
- Download: [MIT VisGel](https://github.com/YunzhuLi/VisGel)

**FabricVST**
- Source: *Multimodal zero-shot learning for tactile texture recognition*
- Download: [MultimodalZSL](https://sites.google.com/view/multimodalzsl)

**CHL_Visual_Tactile_Dataset**
- Source: *Visual and corresponding tactile dataset of flexible material for robots and cross modal perception*
- Download: [Mendeley Data](https://data.mendeley.com/datasets/j7pz7x4wmb/4)
- Note: Contains tactile images from triaxial sensor data (not GelSight)

## 2. Numerical Tactile Signal-Based Datasets

**Penn Haptic Texture Toolkit (HaTT)**
- Source: *One hundred data-driven haptic texture models and open-source methods for rendering on 3D objects*
- Download: [UPenn Repository](https://repository.upenn.edu/meam_papers/299/)

**LMT Haptic Texture Database**
- Source: *A haptic texture database for tool-mediated texture recognition and classification*
- Subsets: TUM-69, LMT-108, LMT-184
- Download: [TUM Haptic Database](https://zeus.lmt.ei.tum.de/downloads/texture/#download)

**Penn Haptic Adjective Corpora**
- PHAC-1: Available in [PHAC-2](#penn-haptic-adjective-corpus-2-phac-2)
- PHAC-2: *Robotic learning of haptic adjectives through physical interaction*
  - Download: [DOI](https://doi.org/10.17617/3.0C79KW)

**AU Dataset**
- Source: *AU Dataset for Visuo-Haptic Object Recognition for Robots*
- Download: [Figshare](https://figshare.com/articles/dataset/AU_Dataset_for_Visuo-Haptic_Object_Recognition_for_Robots/14222486)

**Visuo-Haptic Recognition Dataset**
- Source: *Evaluating Integration Strategies for Visuo-Haptic Object Recognition*
- Download: [Figshare](https://figshare.com/s/555a20d9972e74fae355)

**MREO Dataset**
- Source: *Semi-Supervised Haptic Material Recognition for Robots using Generative Adversarial Networks*
- Download: [mr-gan](https://github.com/Healthcare-Robotics/mr-gan)

**Multimodal Grasp Dataset**
- Source: *Multimodal grasp data set: A novel visualâ€“tactile data set for robotic manipulation*
- Download: [Tsinghua Visual-Tactile](https://github.com/tsinghua-rll/Visual-Tactile_Dataset)

**HapTex**
- Source: *HapTex: A Database of Fabric Textures for Surface Tactile Display*
- Download: [BUAA Fabric Database](http://haptic.buaa.edu.cn/English_FabricDatabase.htm)

**SCT-CNN Dataset**
- Source: *SCT-CNN: A spatio-channel-temporal attention CNN for grasp stability prediction*
- Download: [Zenodo](https://zenodo.org/records/4589825)

**uSkin Slip Dataset**
- Source: *A Robotic Grasping State Perception Framework With Multi-Phase Tactile Information and Ensemble Learning*
- Download: [Zenodo](https://zenodo.org/records/4584809)

**GSA Dataset**
- Source: *Grasp State Assessment of Deformable Objects Using Visual-Tactile Fusion Perception*
- Download: [Grasping Data](https://github.com/swchui/Grasping-state-assessment/graspingdata)

**BiGS Dataset**
- Source: *BiGS: BioTac Grasp Stability Dataset*
- Download: [USC BiGS](http://bigs.robotics.usc.edu/)

## 3. Thermal Imaging Contact Datasets

**ContactDB**
- Source: *Contactdb: Analyzing and Predicting Grasp Contact Via Thermal Imaging*
- Download: [ContactDB Prediction](https://github.com/samarth-robo/contactdb_prediction)
